ğŸ¬ IMDb Movie Review Sentiment Analysis

A Natural Language Processing (NLP) Project

ğŸ“– Overview

This project applies Natural Language Processing (NLP) and Machine Learning to classify IMDb movie reviews as positive or negative.

By using text preprocessing techniques, feature engineering (TF-IDF, embeddings), and classification algorithms, the model is trained to predict the sentiment of reviews with high accuracy.

ğŸ” Use Case: Helps platforms like IMDb, movie producers, and critics to understand public opinion, improve recommendations, and design better marketing strategies.

â“ Problem Statement

The main objective is to build a classification model that predicts the sentiment (positive/negative) of IMDb reviews.

Approach

Data Exploration & Cleaning â†’ Balanced dataset of 50,000 reviews (25k positive, 25k negative).

Preprocessing â†’ Remove stopwords, punctuation, lowercase text, tokenize, lemmatize.

Feature Engineering â†’ TF-IDF vectorization + additional textual features.

Model Development â†’ Train multiple classifiers (Logistic Regression, Naive Bayes, SVM, Random Forest, XGBoost).

Hyperparameter Tuning â†’ Optimize models using GridSearchCV.

ğŸ“‚ Dataset Information

The IMDb dataset contains user-submitted reviews labeled with sentiment.

Field	Description
review	Text of the movie review
sentiment	Positive / Negative

ğŸ“Œ Dataset Size: 50,000 reviews (balanced)

ğŸ“ Project Tasks
ğŸ”¹ Task 1: Data Exploration & Preprocessing (5 Marks)

Checked dataset shape, missing values, class balance.

Explored review lengths distribution.

Performed text cleaning using NLTK:

Lowercasing

Removing HTML tags, punctuation, and special characters

Removing stopwords

Tokenization

Lemmatization

ğŸ”¹ Task 2: Feature Engineering (10 Marks)

TF-IDF Vectorization for text-to-numeric transformation.

Additional textual features:

Word count

Character count

Average word length

ğŸ“ Project Tasks
ğŸ”¹ Task 1: Data Exploration & Preprocessing 

Checked dataset shape, missing values, class balance.

Explored review lengths distribution.

Performed text cleaning using NLTK:

Lowercasing

Removing HTML tags, punctuation, and special characters

Removing stopwords

Tokenization

Lemmatization

ğŸ”¹ Task 2: Feature Engineering 

TF-IDF Vectorization for text-to-numeric transformation.

Additional textual features:

Word count

Character count

Average word length

ğŸ”¹ Task 3: Model Development

Built and evaluated multiple classification models:

Logistic Regression

Naive Bayes (MultinomialNB)

Support Vector Machine (LinearSVC)

Random Forest

XGBoost

âœ”ï¸ Hyperparameter tuning performed using GridSearchCV.

ğŸ”¹ Task 4: Model Evaluation (5 Marks)

Metrics used: Accuracy, Precision, Recall, F1-score

Confusion Matrices plotted

Final Evaluation Table created before & after tuning

Evaluation â†’ Compare performance using accuracy, precision, recall, F1-score.

âš™ï¸ Tools & Libraries

Python 

Data Analysis & ML: pandas, numpy, scikit-learn, xgboost, Random Forest, Naive Bayes, SVM, Logistic Regression

NLP: NLTK, spaCy

Visualization: matplotlib, seaborn, wordcloud

Environment: Jupyter Notebook

ğŸ“Š Deliverables

âœ”ï¸ Jupyter Notebook with code & analysis
âœ”ï¸ Preprocessed dataset & feature representations
âœ”ï¸ Trained models with evaluation results
âœ”ï¸ Visualizations (confusion matrices, word clouds, plots)


